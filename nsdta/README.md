# NSDTA Data Pipeline

A structured data analysis pipeline for sector data analysis using R for data cleaning and statistical inference, with SQLite for data organization and variable construction.

## Project Structure

```
nsdta/
├── data/
│   ├── raw/                    # Raw data files (read-only)
│   │   ├── education/          # Education sector data
│   │   ├── health/             # Health sector data
│   │   ├── law_justice/        # Law and justice sector data
│   │   └── metadata/           # Data dictionaries and metadata
│   └── cleaned/                # Cleaned CSV files (generated)
├── R/                          # R scripts
│   ├── 01_load_clean_education.R
│   ├── 02_load_clean_health.R
│   ├── 03_load_clean_law_justice.R
│   ├── 04_connect_database.R
│   ├── 05_t_tests.R
│   ├── 06_regressions.R
│   └── 07_visualization.R
├── sql/                        # SQL scripts
│   ├── 01_create_schema.sql
│   ├── 02_variable_construction.sql
│   └── 03_descriptive_statistics.sql
├── output/                     # Analysis outputs
│   ├── tables/                 # Statistical tables (CSV)
│   └── figures/                # Plots and visualizations (PNG/PDF)
└── docs/                       # Documentation
```

## Data Pipeline Workflow

### Phase 1: Data Loading and Cleaning (R)
1. Load raw data from `data/raw/` directories
2. Clean and standardize data
3. Export cleaned CSV files to `data/cleaned/`

**Scripts:** `01_load_clean_education.R`, `02_load_clean_health.R`, `03_load_clean_law_justice.R`

### Phase 2: Schema Organization and Variable Construction (SQL)
1. Create SQLite database and import cleaned CSVs
2. Define database schema and relationships
3. Construct derived variables and aggregate measures
4. Generate descriptive statistics views

**Scripts:** `01_create_schema.sql`, `02_variable_construction.sql`, `03_descriptive_statistics.sql`

**Database:** `nsdta_database.db` (created in project root)

### Phase 3: Statistical Inference (R)
1. Connect to SQLite database and load processed data
2. Conduct t-tests comparing sectors and groups
3. Run regression analyses
4. Create visualizations
5. Export results to `output/`

**Scripts:** `04_connect_database.R`, `05_t_tests.R`, `06_regressions.R`, `07_visualization.R`

## Getting Started

### Prerequisites

**R packages:**
```r
install.packages(c("tidyverse", "DBI", "RSQLite", "broom", "ggplot2"))
```

**SQLite:**
```bash
# Ubuntu/Debian
sudo apt-get install sqlite3

# macOS
brew install sqlite3

# Windows: Download from https://www.sqlite.org/download.html
```

### Running the Pipeline

1. **Add raw data files** to the appropriate `data/raw/` subdirectories

2. **Run R cleaning scripts** (Phase 1):
```r
source("R/01_load_clean_education.R")
source("R/02_load_clean_health.R")
source("R/03_load_clean_law_justice.R")
```

3. **Execute SQL scripts** (Phase 2):
```bash
sqlite3 nsdta_database.db < sql/01_create_schema.sql
sqlite3 nsdta_database.db < sql/02_variable_construction.sql
sqlite3 nsdta_database.db < sql/03_descriptive_statistics.sql
```

4. **Run R analysis scripts** (Phase 3):
```r
source("R/04_connect_database.R")
source("R/05_t_tests.R")
source("R/06_regressions.R")
source("R/07_visualization.R")
```

## Data Sectors

- **Education**: Education sector indicators and metrics
- **Health**: Health sector indicators and metrics
- **Law and Justice**: Law and justice sector indicators and metrics

## Output

- **Tables**: Statistical results, regression coefficients, t-test results in `output/tables/`
- **Figures**: Visualizations, diagnostic plots in `output/figures/`

## Documentation

See the `docs/` directory for:
- Detailed methodology
- Analysis plans
- Variable codebooks
- Results summaries

## Notes

- All raw data files should be treated as read-only
- Cleaned data can be regenerated by re-running Phase 1 scripts
- The SQLite database can be recreated by re-running Phase 2 scripts
- Output files can be regenerated by re-running Phase 3 scripts

## License

[Add license information]

## Contact

[Add contact information]
